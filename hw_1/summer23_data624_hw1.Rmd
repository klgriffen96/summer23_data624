---
title: 'Data 624: Predictive Analytics HW 1'
author: "Group 2: Alice Friedman, Kayleah Griffen, Josh Iden, Michael Ippolito"
date: "6/18/2023"
output:
  word_document: default
  html_document:
    df_print: paged
always_allow_html: true
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = FALSE)
```
## Introduction

This homework assignment includes problems from:

(1) Hyndman & Athanasopoulos. "Forecasting: Principles and Practice"
(2) Kuhn & Johnson. "Applied Predictive Modeling"

This accompanies readings from KJ 1,2 and 3 and HA 1,2,6,7 and 8.

## Week 1 Homework Solutions

### HA 2.1

Use the help function to explore what the series `gold`, `woolyrnq` and `gas` represent.

#### a. Use autoplot() to plot each of these in separate plots.

```{r 2.1a, warning = FALSE, message=FALSE}
library(fpp2)
library(gridExtra)
library(tidyverse)


# ?gold
# "Daily morning gold prices in US dollars. 1 January 1985 – 31 March 1989"
# 
# ?woolyrnq
# "Quarterly production of woollen yarn in Australia: tonnes. Mar 1965 – Sep 1994"
# 
# ?gas
# "Australian monthly gas production: 1956–1995."

p1 = autoplot(gold) + ggtitle('Price of Gold: 1985-1989') + ylab('price') + xlab('')
p2 = autoplot(woolyrnq) + ggtitle('Quarterly Production of Woollen Yarn in Australia: 1965 - 1994') + ylab('tonnes') + xlab('')
p3 = autoplot(gas) + ggtitle('Australian monthly gas production: 1956-1995') + ylab('gas') + xlab('')

grid.arrange(p1, p2, p3, nrow=3)
```

#### b. What is the frequency of each series? 

```{r 2.1_frequency}

Gold <- frequency(gold)

Wool <- frequency(woolyrnq)

Gas <- frequency(gas)

Freqs <- data.frame(
  Series = c("Gold", "Wool", "Gas"),
  Frequency = c(Gold, Wool, Gas),
  Seasonality = c("Daily", "Quaterly", "Monthly")
  ) 
Freqs %>% print() 
```

Based on `frequency` and the help function you can tell the `gold` observations are taken daily, the `woolyrnq` is quarterly, and the `gas` is monthly.


#### c. Use which.max() to spot the outlier in the gold series. Which observation was it?

`which.max` determines the index of the maximum of the numeric vector. This occurs at day 770 in the gold series. We can check what date this is using `lubridate` package.

```{r, warning=FALSE, message = FALSE}
library(lubridate)

d <- ymd("1985/01/01") + which.max(gold)

paste0('day:', which.max(gold) ,  '  date:', d, '  price: $', gold[which.max(gold)])

```
The max price of gold occurred on February 10, 1987.

### HA 2.3

#### a. Download some monthly Australian retail data from the book website (https://otexts.com/fpp2/extrafiles/retail.xlsx). These represent retail sales in various categories for different Australian states, and are stored in a MS-Excel file.

Head of the downdloaded dataset is below.

```{r 2.3setup}
library(readxl)
retaildata <- readxl::read_excel("retail.xlsx", skip=1)
head(retaildata)
```

#### b. Select one of the time series as follows (but replace the column name with your own chosen column):

```{r 2.3b}
myts <- ts(retaildata[,"A3349335T"],
  frequency=12, start=c(1982,4))
```

#### c. Explore your chosen retail time series using the following functions:

`autoplot()`, `ggseasonplot()`, `ggsubseriesplot()`, `gglagplot()`, `ggAcf()`


```{r 2.3}

ap <- autoplot(myts) +
  ggtitle("Autoplot: Monthly retail sales in various categories for different Australian states") +
  xlab("Year") +
  ylab("Retail Sales")

sp <- ggseasonplot(myts, year.labels=TRUE, year.labels.left=TRUE) +
  ylab("Retail Sales") +
  ggtitle("Seasonal plot: Monthly retail sales")

gsp <- ggsubseriesplot(myts) +
  ylab("Retail Sales") +
  ggtitle("Subseries Plot: Monthly retail sales")

myts_window <- window(myts, start = c(1982, 4))
win <- ggAcf(myts_window)


grid.arrange(ap, sp, gsp, win, ncol=2)
```



```{r}
lagged <- gglagplot(myts_window) + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) + 
  ggtitle("Lag Plot")
print(lagged)
```

#### Can you spot any seasonality, cyclicity and trend? What do you learn about the series?

* We can see from the autoplot that there is a clear, increasing trend, and there is some seasonality. 

* The lagged scatterplots show that the relationships are strongly positive across all lags, but dramatically positive at lag 12. This indicates a high annual correlation. We can see this in the ACF plot as well. 

* We also notice that the correlation, while remaining positive, becomes less strongly positive as time goes by, and then peaks again every 12 months. 

* The subseries plot shows us that December has the highest average monthly sales and lowest in February, which we can see from the seasonal plot is a trend that is consistent across years.


### HA 6.2

The plastics data set consists of the monthly sales (in thousands) of product A for a plastics manufacturer for five years.

(a) Plot the time series of sales of product A. Can you identify seasonal fluctuations and/or a trend-cycle?

```{r}
# ?plastics
# "Monthly sales of product A for a plastics manufacturer."

autoplot(plastics) +
  ggtitle("Monthly sales of product A for a plastics manufacturer") +
  xlab("Year") +
  ylab("Sales")

ggseasonplot(plastics, year.labels=TRUE, year.labels.left=TRUE) +
  ylab("Sales") +
  ggtitle("Monthly sales of product A for a plastics manufacturer")

ggsubseriesplot(plastics) +
  ylab("Sales") +
  ggtitle("Monthly sales of product A for a plastics manufacturer")
```

Based on the plots there does appear to be seasonality to the data, the plastic sales are highest May - October (peaking in August usually) and lower November - April (lowest in February). 

(b) Use a classical multiplicative decomposition to calculate the trend-cycle and seasonal indices.

```{r}
plastics %>% decompose(type="multiplicative") %>%
  autoplot() + xlab("Year") +
  ggtitle("Classical multiplicative decomposition
    of plasatic sales")
```

The trend cycle shows a strong seasonal component, with a yearly frequency, and has an increasing trend up until just past year 5 when it begins decreasing. There is some remainder as well. The remainder values below 1 indicate that there is some “leakage” of the trend-cycle component into the remainder component - the trend-cycle estimate has over-smoothed the drop in data.

(c) Do the results support the graphical interpretation from part a?

Yes, the graphical interpretation from part A aligns with the multiplicative decomposition. The yearly seasonal pattern was noted in both a and b. The only part that was not captured well is the drop off in the trend after year 5. 

(d) Compute and plot the seasonally adjusted data.


```{r}
fit <- plastics %>%
  decompose(type="multiplicative") 

autoplot(plastics, series="Data") +
  autolayer(trendcycle(fit), series="Trend") +
  autolayer(seasadj(fit), series="Seasonally Adjusted") +
  xlab("Year") + ylab("Sales") +
  ggtitle("Monthly sales of product A for a plastics manufacturer") +
  scale_colour_manual(values=c("gray","blue","red"),
             breaks=c("Data","Seasonally Adjusted","Trend"))

```

(e) Change one observation to be an outlier (e.g., add 500 to one observation), and recompute the seasonally adjusted data. What is the effect of the outlier?

```{r}

plastics_outlier_1 <- plastics
plastics_outlier_1[10] <- plastics[10] + 500

fit <- plastics_outlier_1 %>%
  decompose(type="multiplicative") 

autoplot(plastics_outlier_1, series="Data") +
  autolayer(trendcycle(fit), series="Trend") +
  autolayer(seasadj(fit), series="Seasonally Adjusted") +
  xlab("Year") + ylab("Sales") +
  ggtitle("Monthly sales of product A for a plastics manufacturer") +
  scale_colour_manual(values=c("gray","blue","red"),
             breaks=c("Data","Seasonally Adjusted","Trend"))


plastics_outlier_1 %>% decompose(type="multiplicative") %>%
  autoplot() + xlab("Year") +
  ggtitle("Classical multiplicative decomposition
    of plastic sales")

```

The effect of the outlier on the seasonally adjusted data is that there is now a peak at the 10th observation, the spike in the data is not accounted for in the moving average trend due to the moving average smoothing out the outlier so it comes through in the seasonally adjusted. You can see however that even though the data went up by 500, the seasonally adjusted only went up by half of that. You can see that some of the difference that the outlier made went into the remainder.

(f) Does it make any difference if the outlier is near the end rather than in the middle of the time series?

```{r}
#refactor as function

outlier <- function(n, v){
  plastics_outlier_2 <- plastics
  plastics_outlier_2[n] <- plastics[n] + v

  fit <- plastics_outlier_2 %>%
    decompose(type="multiplicative") 

  autoplot(plastics_outlier_2, series="Data") +
    autolayer(trendcycle(fit), series="Trend") +
    autolayer(seasadj(fit), series="Seasonally Adjusted") +
    xlab("Year") + ylab("Sales") +
    ggtitle("Monthly sales of product A for a plastics manufacturer") +
    scale_colour_manual(values=c("gray","blue","red"),
               breaks=c("Data","Seasonally Adjusted","Trend"))
  
}

outlier(60,500)
outlier(30, 500)

```

If the outlier is at the end vs in the middle, there is more of an effect on the seasonally adjusted data. The estimate of the trend cycle is unavailable for the first and last few observations - without this there is also no estimate of the remainder component. Due to this, all of the outlier is passed on to the seasonally adjusted rather than having some of it put in the remainder or in the trend.

## Week 2 Homework Solutions

### HA 7.1

Consider the `pigs` series -- the number of pigs slaughtered in Victoria each month.

### 7.1 a 
Use the `ses` function to find the optimal levels of alpha and l-zero, and generate forecasts for the next 4 months.

```{r 7.1a}
fit_pigs <- pigs %>% ses(h=4)

fit_pigs %>% autoplot()

summary(fit_pigs)
```

### 7.1 b
 Compute a 95% prediction interval for the first forecast using y-hat is plus or minus 1.96s where `s` is the standard deviation of the residuals. Compare your interval with the interval produced by R.
```{r 7.1b}
me <- 1.96*sd(fit_pigs$residuals)

f1 <- fit_pigs$mean[1]


```

The first forecast is `r f1` with a 95% margin of error plus or minus `r me`. 

```{r 7.1b_table}
library(dplyr)
labels_7.1b <- c("My Results", "R")
my_pigs <- c(f1-me, f1+me)
R_pigs <- c(fit_pigs$lower[5], fit_pigs$upper[5])
df_pigs <- data.frame(my_pigs, R_pigs)
colnames(df_pigs) <- labels_7.1b
row.names(df_pigs) <- c("Lower 95% Bound", "Upper 95% Bound")
df_pigs <- df_pigs %>% mutate(
  `% Diff` = (`My Results` - R)/R*100
)

df_pigs %>% t()
```


### HA 7.3
(In the previous exercise, we we asked to write our own function to implement simple exponential smoothing.)

Modify your function from the previous exercise to return the sum of the squared errors rather than the forecast of the next observations. The use the `optim` function to find the optimal methods of alpha and l-0. Do you get the same values as the `ses()` function?

There is not difference depending on the level for moderate values of alpha, but for small alpha it does make a difference.

```{r 7.2}
T <- length(pigs) %>% as.numeric()
my_smooth <- function(y, alpha, level) {
  
  T <- length(y) %>% as.numeric()
  
  my_fitted <- c()
  
  #set first value 
  my_fitted[1] <- level

    # I really wish we could do this wihout a for loop!!!
    # Also I don't understand why this doesn't have the exponential or summation??
    for (i in 2:(T+1)) {
    my_fitted[i] <- alpha * y[i-1] + (1 - alpha) * my_fitted[i-1]
  }
  
  #return last value
  return(my_fitted)
  }

alpha <- 0.291
level <- pigs[1]

my_smooth(pigs, alpha=alpha, level=level)[T+1]
my_smooth(pigs, alpha=alpha, level=level/2)[T+1]
my_smooth(pigs, alpha=1/T, level=level)[T+1]
my_smooth(pigs, alpha=1/T, level=level/2)[T+1]

ses(pigs, alpha=alpha)$mean[1]

```

```{r 7.3sse}
my_sse <- function(y, alpha, level) {
  
  y_hats <- my_smooth(y, alpha, level)
  resid <- y_hats - y
  sse <- mapply(function(x) x^2, resid) %>% sum()

  return(sse)

}
```

Then use the `optim` function to find the optimal methods of alpha and l-0. 
 ## NOT DONE!
```{r 7.3optim}

```

## KJ 3.1
```{r 3.1}
library(mlbench)
data(Glass)
str(Glass)
```

### 3.1a
Using visualizations, explore the predictor variables to understand their distributions as well as the relationships between predictors.

```{r 3.1a_pLots, message=FALSE, warning=FALSE}

Glass %>% select(-Type) %>% gather() %>% ggplot(aes(value)) + geom_histogram() + facet_wrap(~key, scales = "free")

Glass %>% select(-Type) %>% gather() %>% ggplot(aes(value)) + geom_boxplot() + facet_wrap(~key, scales = "free")

```

```{r 3.1a_targetPLots}
Glass %>% gather("key", "value", -Type) %>% 
  ggplot(aes(factor(Type), value)) + 
  geom_boxplot() + 
  facet_wrap(~key, scales = "free") 

```

```{r 3.1a_corrPLots}
# Added from Michael's

# Filter for just quantitative vars
glassQuant <- Glass %>% select (-Type)

# Corr chart
chart.Correlation(glassQuant)
```

### 3.1b
Do there appear to be any outliers? Are any predictors skewed?

```{r 3.1b}
library(psych)
describe(Glass)

```

## KJ 3.2



```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```

