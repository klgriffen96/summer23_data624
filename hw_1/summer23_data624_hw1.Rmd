---
title: 'Data 624: Predictive Analytics HW 1'
author: "Group 2: Alice Friedman, Kayleah Griffen, Josh Iden, Michael Ippolito"
date: "6/18/2023"
output:
  word_document: default
  html_document:
    df_print: paged
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Introduction

This homework assignment includes problems from:

(1) Hyndman & Athanasopoulos. "Forecasting: Principles and Practice"
(2) Kuhn & Johnson. "Applied Predictive Modeling"

This accompanies readings from KJ 1,2 and 3 and HA 1,2,6,7 and 8.

## Week 1 Homework Solutions

### HA 2.1

Using the help function (`?`) to explore what the series `gold`, `woolyrnq` and `gas` represent, we get the following results in the description:

?gold
 "Daily morning gold prices in US dollars. 1 January 1985 – 31 March 1989"
 
?woolyrnq
"Quarterly production of woollen yarn in Australia: tonnes. Mar 1965 – Sep 1994"
 
?gas
Australian monthly gas production: 1956–1995.


#### a. Use autoplot() to plot each of these in separate plots.

```{r 2.1a, warning = FALSE, message=FALSE}
library(fpp2)
library(gridExtra)
library(tidyverse)



p1 = autoplot(gold) + ggtitle('Price of Gold: 1985-1989') + ylab('price') + xlab('')
p2 = autoplot(woolyrnq) + ggtitle('Quarterly Production of Woollen Yarn in Australia: 1965 - 1994') + ylab('tonnes') + xlab('')
p3 = autoplot(gas) + ggtitle('Australian monthly gas production: 1956-1995') + ylab('gas') + xlab('')

grid.arrange(p1, p2, p3, nrow=3)
```

#### b. What is the frequency of each series? 

```{r 2.1_frequency}

Gold <- frequency(gold)

Wool <- frequency(woolyrnq)

Gas <- frequency(gas)

Freqs <- data.frame(
  Series = c("Gold", "Wool", "Gas"),
  Frequency = c(Gold, Wool, Gas),
  Seasonality = c("Daily", "Quaterly", "Monthly")
  ) 
Freqs %>% print() 
```

Based on `frequency` and the help function you can tell the `gold` observations are taken daily, the `woolyrnq` is quarterly, and the `gas` is monthly.


#### c. Use which.max() to spot the outlier in the gold series. Which observation was it?

`which.max` determines the index of the maximum of the numeric vector. This occurs at day 770 in the gold series. We can check what date this is using `lubridate` package.

```{r, warning=FALSE, message = FALSE}
library(lubridate)

d <- ymd("1985/01/01") + which.max(gold)

paste0('day:', which.max(gold) ,  '  date:', d, '  price: $', gold[which.max(gold)])

```
The max price of gold occurred on February 10, 1987.

### HA 2.3

#### a. Download some monthly Australian retail data from the book website (https://otexts.com/fpp2/extrafiles/retail.xlsx). These represent retail sales in various categories for different Australian states, and are stored in a MS-Excel file.

Head of the downdloaded dataset is below.

```{r 2.3setup}
library(readxl)
retaildata <- readxl::read_excel("retail.xlsx", skip=1)
head(retaildata)
```

#### b. Select one of the time series as follows (but replace the column name with your own chosen column):

```{r 2.3b}
myts <- ts(retaildata[,"A3349335T"],
  frequency=12, start=c(1982,4))
```

#### c. Explore your chosen retail time series using the following functions: `autoplot()`, `ggseasonplot()`, `ggsubseriesplot()`, `gglagplot()`, `ggAcf()`

Below we plotted `autoplot()`, `ggseasonplot()`, `ggsubseriesplot()`, & ` ggAcf()` in a grid. The lag plot requires a lot of space so it is plotted seperately!

```{r 2.3}
ap <- autoplot(myts) +
  ggtitle("Autoplot: Monthly retail sales in various categories for different Australian states") +
  xlab("Year") +
  ylab("Retail Sales")

sp <- ggseasonplot(myts, year.labels=TRUE, year.labels.left=TRUE) +
  ylab("Retail Sales") +
  ggtitle("Seasonal plot: Monthly retail sales")

gsp <- ggsubseriesplot(myts) +
  ylab("Retail Sales") +
  ggtitle("Subseries Plot: Monthly retail sales")

myts_window <- window(myts, start = c(1982, 4))
win <- ggAcf(myts_window)


grid.arrange(ap, sp, gsp, win, ncol=2)
```

```{r}
lagged <- gglagplot(myts_window) + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) + 
  ggtitle("Lag Plot")
print(lagged)
```

#### Can you spot any seasonality, cyclicity and trend? What do you learn about the series?

* From the autoplot, we can see from the that there is a clear, increasing trend, as well as seasonality. 

* From the seasonal trend, it is easier to see that that the seasonality has an annual frequency which is additionally following a steady upward trend over time.

* The subseries plot again shows the trend clearly -- within each month there is a steady upward trend that appears to have roughly the same slope every month indicating that the trend is consistent across years.

* The window plot shows a clear trend (rather than white noise) which indicates that there is strong autocorrelation in the series.

* Finally, the lagged scatterplots show that the relationships are strongly positive across all lags, but dramatically positive at lag 12. This indicates a high annual correlation. We can see this in the ACF plot as well. We also notice that the correlation, while remaining positive, becomes less strongly positive as time goes by, and then peaks again every 12 months, again pointing to the 12 monthly frequency.


### HA 6.2

The `plastics` data set consists of the monthly sales (in thousands) of product A for a plastics manufacturer for five years.

#### a. Plot the time series of sales of product A. Can you identify seasonal fluctuations and/or a trend-cycle?

```{r 6.2a}
# ?plastics
# "Monthly sales of product A for a plastics manufacturer."

autoplot(plastics) +
  ggtitle("Monthly sales of product A for a plastics manufacturer") +
  xlab("Year") +
  ylab("Sales")
```

Based on the autoplot there does appear to be seasonality to the data, the plastic sales are highest May - October (peaking in August usually) and lower November - April (lowest in February). There is a consistent upward trend-cycle as well. 

#### b. Use a classical multiplicative decomposition to calculate the trend-cycle and seasonal indices.

We use the `decompose` function with `type="mutliplicative"` and then `autoplot` to decompose the series and then evalaute the results.

```{r 6.2b}
plastics %>% decompose(type="multiplicative") %>%
  autoplot() + xlab("Year") +
  ggtitle("Classical multiplicative decomposition
    of plasatic sales")
```

The trend cycle shows a strong seasonal component, with a yearly frequency, and has an increasing trend up until just past year 5 when it begins decreasing. There is some remainder as well. The remainder values below 1 indicate that there is some “leakage” of the trend-cycle component into the remainder component - the trend-cycle estimate has over-smoothed the drop in data.

#### c. Do the results support the graphical interpretation from part a?

Yes, the graphical interpretation from part A aligns with the multiplicative decomposition. The yearly seasonal pattern was noted in both a and b. The only part that was not captured well is the drop off in the trend after year 5. 

#### d. Compute and plot the seasonally adjusted data.

We can compute the seasonally adjusted fit by applying the `seasadj` function to the decomposed time series.

```{r 6.2d, warning=FALSE}
fit <- plastics %>%
  decompose(type="multiplicative") 

autoplot(plastics, series="Data") +
  autolayer(trendcycle(fit), series="Trend") +
  autolayer(seasadj(fit), series="Seasonally Adjusted") +
  xlab("Year") + ylab("Sales") +
  ggtitle("Monthly sales of product A for a plastics manufacturer") +
  scale_colour_manual(values=c("gray","blue","red"),
             breaks=c("Data","Seasonally Adjusted","Trend"))

```

#### e. Change one observation to be an outlier (e.g., add 500 to one observation), and recompute the seasonally adjusted data. What is the effect of the outlier?

```{r 6.2e, warning=FALSE}
outlier <- function(n, v, outlier){
  if(outlier==TRUE){
    
    plastics[n] <- v
    subtitle <- paste("Outlier is", v, "at month", n)

    
  } else {
    subtitle <- "Original data"

  }
  
    fit <- plastics %>% decompose(type="multiplicative") 


  autoplot(plastics, series="Data") +
    autolayer(seasadj(fit), series="Seasonally Adjusted") +
    xlab("Year") + ylab("Sales") +
    labs(
      title = "Monthly sales of product A for a plastics manufacturer",
      subtitle = subtitle
      ) +
    scale_colour_manual(values=c("gray","blue"),
               breaks=c("Data","Seasonally Adjusted","Trend")) + 
    scale_y_continuous(expand = c(0, 0), limits = c(0, NA))

  
}

grid.arrange(
  outlier(1, 1, FALSE),
  outlier(59, 50, TRUE),
  outlier(30, 50, TRUE), 
  ncol=1
)

```

The outlier in the middle causes the seasonally adjusted fit to hallucinate seasons that don't exist! At or near the end, there is no discernable effect.

#### f. Does it make any difference if the outlier is near the end rather than in the middle of the time series?

Yes -- the outlier in the middle has a much more pronounced affect than an outlier at the end.

If the outlier is at the end vs in the middle, there is more of an effect on the seasonally adjusted data. The estimate of the trend cycle is unavailable for the first and last few observations - without this there is also no estimate of the remainder component. Due to this, all of the outlier is passed on to the seasonally adjusted rather than having some of it put in the remainder or in the trend.

## Week 2 Homework Solutions

### HA 7.1

Consider the `pigs` series -- the number of pigs slaughtered in Victoria each month.

### 7.1 a 
Use the `ses` function to find the optimal levels of alpha and l-zero, and generate forecasts for the next 4 months.

```{r 7.1a}
fit_pigs <- pigs %>% ses(h=4)

fit_pigs %>% autoplot()

summary(fit_pigs)
```

### 7.1 b
 Compute a 95% prediction interval for the first forecast using y-hat is plus or minus 1.96s where `s` is the standard deviation of the residuals. Compare your interval with the interval produced by R.
```{r 7.1b}
me <- 1.96*sd(fit_pigs$residuals)

f1 <- fit_pigs$mean[1]


```

The first forecast is `r f1` with a 95% margin of error plus or minus `r me`. 

```{r 7.1b_table}
library(dplyr)
labels_7.1b <- c("My Results", "R")
my_pigs <- c(f1-me, f1+me)
R_pigs <- c(fit_pigs$lower[5], fit_pigs$upper[5])
df_pigs <- data.frame(my_pigs, R_pigs)
colnames(df_pigs) <- labels_7.1b
row.names(df_pigs) <- c("Lower 95% Bound", "Upper 95% Bound")
df_pigs <- df_pigs %>% mutate(
  `% Diff` = (`My Results` - R)/R*100
)

df_pigs %>% t()
```


### HA 7.3
(In the previous exercise, we we asked to write our own function to implement simple exponential smoothing.)

Modify your function from the previous exercise to return the sum of the squared errors rather than the forecast of the next observations. The use the `optim` function to find the optimal methods of alpha and l-0. Do you get the same values as the `ses()` function?

There is not difference depending on the level for moderate values of alpha, but for small alpha it does make a difference.

```{r 7.2}
T <- length(pigs) %>% as.numeric()
my_smooth <- function(y, alpha, level) {
  
  T <- length(y) %>% as.numeric()
  
  my_fitted <- c()
  
  #set first value 
  my_fitted[1] <- level

    # I really wish we could do this wihout a for loop!!!
    # Also I don't understand why this doesn't have the exponential or summation??
    for (i in 2:(T+1)) {
    my_fitted[i] <- alpha * y[i-1] + (1 - alpha) * my_fitted[i-1]
  }
  
  #return last value
  return(my_fitted)
  }

alpha <- 0.291
level <- pigs[1]

my_smooth(pigs, alpha=alpha, level=level)[T+1]
my_smooth(pigs, alpha=alpha, level=level/2)[T+1]
my_smooth(pigs, alpha=1/T, level=level)[T+1]
my_smooth(pigs, alpha=1/T, level=level/2)[T+1]

ses(pigs, alpha=alpha)$mean[1]

```

```{r 7.3sse}
my_sse <- function(y, alpha, level) {
  
  y_hats <- my_smooth(y, alpha, level)
  resid <- y_hats - y
  sse <- mapply(function(x) x^2, resid) %>% sum()

  return(sse)

}
```

Then use the `optim` function to find the optimal methods of alpha and l-0. 
 ## NOT DONE!
```{r 7.3optim}

```

## KJ 3.1
```{r 3.1}
library(mlbench)
data(Glass)
str(Glass)
```

### 3.1a
Using visualizations, explore the predictor variables to understand their distributions as well as the relationships between predictors.

```{r 3.1a_pLots, message=FALSE, warning=FALSE}

Glass %>% select(-Type) %>% gather() %>% ggplot(aes(value)) + geom_histogram() + facet_wrap(~key, scales = "free")

Glass %>% select(-Type) %>% gather() %>% ggplot(aes(value)) + geom_boxplot() + facet_wrap(~key, scales = "free")

```

```{r 3.1a_targetPLots}
Glass %>% gather("key", "value", -Type) %>% 
  ggplot(aes(factor(Type), value)) + 
  geom_boxplot() + 
  facet_wrap(~key, scales = "free") 

```

```{r 3.1a_corrPLots}
# Added from Michael's

# Filter for just quantitative vars
glassQuant <- Glass %>% select (-Type)

# Corr chart
chart.Correlation(glassQuant)
```

### 3.1b
Do there appear to be any outliers? Are any predictors skewed?

```{r 3.1b}
library(psych)
describe(Glass)

```

## KJ 3.2



```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```

