---
title: "DATA 624 PROJECT1"
author: "Josh Iden"
date: "`r Sys.Date()`"
output: 
  rmdformats::readthedown:
    code_folding: show
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction 

This report is intended for colleagues from a variety of backgrounds and contains both technical and non-technical explanations of the work conducted. The objective of this project was to perform the appropriate analysis in order to forecast two variables (of five provided) each from six different time series sets. We were provided a spreadsheet that contains 1622 periods of every variable in every set and were expected to forecast 140 periods. The sets are labeled S01, S02, S03, S04, S05 and S06 and each contains variables labeled V01, V02, V03, V05, and V07. Different variables are required to be forecast depending on the set, specified below:

- S01 – Forecast  Var01, Var02  
- S02 – Forecast  Var02, Var03   
- S03 – Forecast  Var05, Var07  
- S04 – Forecast  Var01, Var02  
- S05 – Forecast  Var02, Var03  
- S06 – Forecast  Var05, Var07 


For each category, we perform the following:

1. *Exploratory Data Analysis*
- Visualize the data
- Identify trend, seasonality, stationarity, outliers, missing data, variance, etc. Interpret ACF and PACF to inform modeling approach.
2. *Data Preparation*
- Prepare data for modeling, address outliers, missing values, stationarity, etc. 
- Split data into training and testing sets. 
3. *Data Modeling*
- Prepare models. For this project, we base model accuracy using MAPE (Mean Absolute Percentage Error), selecting the model with the lowest score. 
- Data Export. Using the best model, we predict the next 140 periods and write to disk. 

# Data Import 

We read in the data and create separate data frames containing only the first 1622 observations. 

```{r, message = FALSE, warning = FALSE, echo = FALSE}
library(httr)
library(kableExtra)
library(forecast)

github_link <- "https://github.com/klgriffen96/summer23_data624/raw/main/project_1/Data%20Set%20for%20Class.xls"
temp_file <- tempfile(fileext = ".xls")
req <- GET(github_link, 
          # write result to disk
           write_disk(path = temp_file))

df <- readxl::read_excel(temp_file)

head(df, 10) |>
  kbl(caption = "Series Provided") |>
  kable_classic(full_width = F, html_font = "Cambria")
```

```{r, warning=FALSE, message = FALSE, echo = FALSE}
library(tidyverse)
s1 <- df |> filter(category == "S01") |> slice(1:1622)
s2 <- df |> filter(category == "S02") |> slice(1:1622)
s3 <- df |> filter(category == "S03") |> slice(1:1622)
s4 <- df |> filter(category == "S04") |> slice(1:1622)
s5 <- df |> filter(category == "S05") |> slice(1:1622)
s6 <- df |> filter(category == "S06") |> slice(1:1622)

head(s1, 5) |>
  kbl(caption = "s01") |>
  kable_classic(full_width = F, html_font = "Cambria")
```

# S01

```{r}
par(mfrow = c(1,2))

s1 |>
  select(c(Var01,Var02)) |>
  ts() |>
  autoplot(facets = TRUE, main = "S01") +
  ylab('')

s1 |>
  ggplot(aes(x = Var01, y = Var02)) +
  geom_point()
```

## Var01

#### Exploratory Data Analysis

```{r}
v1 <- ts(s1$Var01)
ggtsdisplay(v1)
```

* The data is *non-stationary**
* There are two missing values
* The *ACF* is highly significant across many lags
* The *PACF* cuts off at lag 1
* There are some outliers though they are difficult to observe
* There is an upward trend
* Variance appears to be stable 
* There is some cyclicity in the data. There does not appear to be any seasonality 
* The data is non-linear

We can see the lags are highly correlated using a lagplot,

```{r}
gglagplot(v1)
```


We can visualize the missing values to see where they appear within the data using the `imputeTS` package, which we can later use to impute the missing values using a moving average. 

```{r}
library(imputeTS)
v1 |>
  ggplot_na_distribution()
```


#### Data Preparation

To deal with the outliers, we'll use the `tsclean` function from the `forecast` package, which uses median absolute deviation (MAD) to identify outliers and replace them with imputed values based on neighboring observations. 

For the missing values, we'll use the `na_ma()` function in the `imputeTS` package, which replaces missing values with the weighted moving average of neighboring observations within a specific window. 

```{r}
library(forecast)
v1 <- v1 |>
  tsclean(lambda = "auto") |>
  na_ma() # default window = 4
```

We take a first difference of the data to see if we can achieve stationarity, 

```{r}
v1.diff <- diff(v1)
ggtsdisplay(v1.diff)
```

There are still some outliers and significant values, but the ACF and PACF plots are informative: the ACF cuts off at lag 2,  indicating a MA(2) component. The PACF also cuts off at lag 2, indication an AR(2) component. 

Now we split the data into testing and training sets to prepare for modeling, setting aside 20% of the data for testing. 

```{r}
library(zeallot) # provides tuple assigment

train_test_split <- function(x, split) {
  split.index <- round(length(x) * split) # split point index
  train <- window(x, end = split.index)
  test <- window(x, start = split.index + 1)
  horizon = length(test)
  
  return(list(train, test, horizon))
}

c(train, test, horizon) %<-% train_test_split(v1, 0.8)
```


#### Data Modeling

*Simple Exponential Smoothing* and *Holt's Method*

```{r}
set.seed(123)
ses.fit <- ses(train, h = horizon)
ses.acc <- c(v1 = accuracy(ses.fit, test)['Test set', 'MAPE'])
holt.fit <- holt(train, damped=TRUE, h = horizon)
holt.acc <- c(v1 = accuracy(holt.fit, test)['Test set', 'MAPE'])
cbind(ses = ses.acc, holt = holt.acc)
```

```{r}
Box.test(residuals(holt.fit))$p.value
```

```{r}
Box.test(residuals(ses.fit))$p.value
```


```{r}
autoplot(train) +
  autolayer(ses.fit, series = "ses") +
  autolayer(holt.fit, alpha = 0.4, series = "holt") +
  autolayer(test, series = "test data")
```


*ETS Modeling*  

```{r}
set.seed(123)
ets.fit <- ets(train, model = "MMN")
ets.fit
```

A multiplicative error, multiplicative trend, no seasonality gives us the best model, but there are still problems as there is significance in the ACF: the model is not incorporating all the information in the data, which we can see in the residuals, 

```{r}
checkresiduals(ets.fit)
```
```{r}
set.seed(123)
ets.fc <- forecast(ets.fit, h = horizon)
ets.acc <- c(v1 = accuracy(ets.fc, test)['Test set', 'MAPE'])
cbind(ses = ses.acc, holt = holt.acc, ets = ets.acc)
```

```{r}
autoplot(train) +
  autolayer(ets.fc, series = "ets") +
  autolayer(test, series = "test data")
```

*ARIMA Modeling*

An ARIMA(2,1,2) model with log transformation (`lambda=0`) achieves the best MAPE. 

```{r}
set.seed(123)
arima.fc <- train |>
  Arima(order=c(2,1,2), lambda=0) |>
  forecast(h=horizon)

checkresiduals(arima.fc)
```

```{r}
set.seed(123)
arima.acc <- c(v1 = accuracy(arima.fc, test)['Test set', 'MAPE'])
cbind(ses = ses.acc, holt = holt.acc, ets = ets.acc, arima = arima.acc)
```


#### Results 

```{r}
s1v1.results <- cbind(ses = ses.acc, holt = holt.acc, ets = ets.acc, arima = arima.acc)
```


## Var02 

#### Exploratory Data Analysis 

```{r}
v2 <- ts(s1$Var02)
ggtsdisplay(v2)
```

* This data has a lot of outliers
* There is a faint downward trend over time
* The variance in the data appears to decrease over time
* There is a strong autocorrelation among many lags
* There is no missing data
* The data is non-stationary
* There doesn't appear to be any seasonality

```{r}
gglagplot(v2)
```

Although the ACF plot shows a highly significant autocorrelation, the lags show an inverse correlation between the time series and its lagged values. 

#### Data Preparation 

Dealing with outliers and non-stationarity, applying log transformation to deal with the inverse autocorrelation

```{r}
v2 <- v2 |>
  tsclean(lambda = "auto") |>
  log()

ggtsdisplay(diff(diff(v2)))
```

A second-difference, log tranformation brings the data into stationarity. 

We see the ACF cuts off at Lag 1, suggesting an MA(1) component, while the PACF trails off, further suggesting the MA(1) component. 

```{r}
gglagplot(diff(diff(log(v2))))
```

We can see the inverse correlations in the lags are no longer present.

Now we set aside our training and testing sets. 

```{r}
c(train, test, horizon) %<-% train_test_split(v2, 0.8)
```


#### Data Modeling

*Simple Exponential Smoothing* and *Holt's Method*

```{r}
set.seed(123)
ses.fit <- ses(train, h = horizon)
ses.acc <- c(v2 = accuracy(ses.fit, test)['Test set', 'MAPE'])
holt.fit <- holt(train, damped=TRUE, h = horizon)
holt.acc <- c(v2 = accuracy(holt.fit, test)['Test set', 'MAPE'])
cbind(ses = ses.acc, holt = holt.acc)
```

```{r}
autoplot(train) +
  autolayer(ses.fit, series = "ses") +
  autolayer(holt.fit, alpha = 0.4, series = "holt") +
  autolayer(test, series = "test data")
```

*ETS Modeling*  

```{r}
set.seed(123)
ets.fit <- ets(train)
ets.fit
```

```{r}
checkresiduals(ets.fit)
```
The p-value is far too small to be useful, but we'll make the predictions and store the results for continuity, 

```{r}
set.seed(123)
ets.fc <- forecast(ets.fit, h = horizon)
ets.acc <- c(v2 = accuracy(ets.fc, test)['Test set', 'MAPE'])
cbind(ses = ses.acc, holt = holt.acc, ets = ets.acc)
```


*ARIMA modeling*

```{r}
set.seed(123)
train |>
  auto.arima(lambda = 0) |>
  forecast(h = horizon) |>
  checkresiduals()
```
The p-value of the residuals is still too low to be considered a good model, but it's the best we've found so far, 

```{r}
set.seed(123)
arima.fc <- train |>
  Arima(order=c(1,1,4), lambda=0) |>
  forecast(h=horizon)

checkresiduals(arima.fc)
```
```{r}
set.seed(123)
arima.acc <- c(v2 = accuracy(arima.fc, test)['Test set', 'MAPE'])
arima.acc
```

```{r}
autoplot(train) +
  autolayer(arima.fc, series = "arima") +
  autolayer(test, series = "test data")
```

#### Results 

```{r}
s1v2.results <- cbind(ses = ses.acc, holt = holt.acc, ets = ets.acc, arima = arima.acc)

cat("\tMAPE results by model - S01\n\n")
rbind(s1v1.results,s1v2.results)
```

# S02 

```{r}
par(mfrow = c(1,2))

s2 |>
  select(c(Var02,Var03)) |>
  ts() |>
  autoplot(facets = TRUE, main = "S02") +
  ylab('')

s2 |>
  ggplot(aes(x = Var02, y = Var03)) +
  geom_point()
```

## Var02 



#### Exploratory Data Analysis

```{r}
v2 <- ts(s2$Var02)
ggtsdisplay(v2)
```

* The data is non-stationary
* There is a very faint downward trend over time. 
* There is high variance in the data
* There does not appear to be any seasonality in the data
* The ACF plot indicates the lags are highly significant and trail off over time, indicating an AR component. The PACF model cuts off after 8, indicating an MA component.  
* There are many outliers in the data
* There are no missing values in the data

```{r}
gglagplot(v2)
```

The lags show an inverse correlation. 


#### Data Preparation 

Dealing with outliers and non-stationarity, applying log transformation to deal with the inverse autocorrelation

```{r}
v2 <- v2 |>
  tsclean(lambda = "auto")

ggtsdisplay(diff(log(v2)))
```

The data now appears stationary. The ACF cuts off at 2 indicating an MA(2) component, the PACF cuts off at 9, indicating an AR(9) component.

We can see the inverse correlations in the lags are no longer present.

Now we set aside our training and testing sets. 

```{r}
c(train, test, horizon) %<-% train_test_split(v2, 0.8)
```


#### Data Modeling

*Simple Exponential Smoothing* and *Holt's Method*


```{r}
set.seed(123)
ses.fit <- ses(train, h = horizon)
ses.acc <- c(v2 = accuracy(ses.fit, test)['Test set', 'MAPE'])
holt.fit <- holt(train, damped=TRUE, h = horizon)
holt.acc <- c(v2 = accuracy(holt.fit, test)['Test set', 'MAPE'])
cbind(ses = ses.acc, holt = holt.acc)
```

```{r}
rbind(holt_pval = Box.test(residuals(holt.fit))$p.value,
      ses_pval = Box.test(residuals(ses.fit))$p.value)
```

The p-values are very low. These models do not fit the data well. 

```{r}
autoplot(train) +
  autolayer(ses.fit, series = "ses") +
  autolayer(holt.fit, alpha = 0.4, series = "holt") +
  autolayer(test, series = "test data") + 
  ylab("")
```

*ETS Modeling*  

```{r}
set.seed(123)
train.diff <- diff(log(train))
ets.fit <- ets(train.diff)
ets.fit
```

Because we differenced and logged the forecasts, we need to back transfrom the forecasts to match the test data.

```{r}
library(stats)
set.seed(123)
ets.fc <- forecast(ets.fit, h = horizon)
ets.fc <- exp(cumsum(ets.fc$mean))
ets.acc <- c(v2 = accuracy(ets.fc, test)['Test set', 'MAPE'])

cbind(ses = ses.acc, holt = holt.acc, ets = ets.acc)
```

```{r}
checkresiduals(ets.fc)
```
We can see that this model also does not fit the data very well, 


*ARIMA modeling*

```{r}
set.seed(123)
train |>
  auto.arima(lambda = 0) |>
  forecast(h = horizon) |>
  checkresiduals()
```

```{r}
set.seed(123)
arima.fc <- train |>
  auto.arima(lambda=0) |>
  forecast(h=horizon)

arima.acc <- c(v2 = accuracy(arima.fc, test)['Test set', 'MAPE'])
arima.acc
```


```{r}
autoplot(train) +
  autolayer(arima.fc, series = "arima") +
  autolayer(test, series = "test data") + 
  ylab("")
```


This model fits the data pretty well. 

#### Results

```{r}
s2v2.results <- cbind(ses = ses.acc, holt = holt.acc, ets = ets.acc, arima = arima.acc)
s2v2.results
```


## Var03 


#### Exploratory Data Analysis

```{r}
v3 <- ts(s2$Var03)
ggtsdisplay(v3)
```

* The data is non-stationary
* There is no noticeable trend over time 
* There are four missing values
* There is one extreme outlier
* There does not appear to be any seasonality in the data
* The ACF plot indicates the lags are highly significant and trail off over time, indicating an AR component. The PACF model cuts off at lag 1, indicating an AR(1) component.  


```{r}
gglagplot(v3)
```

The lags show a positive linear correlation over shorter periods of time and inverse correlation over longer periods. 

#### Data Preparation 

Dealing with outliers and non-stationarity, applying log transformation to deal with the inverse autocorrelation

```{r}
v3 <- v3 |>
  tsclean(lambda = "auto") |>
  na_ma()

ggtsdisplay(v3)
```

Let's take a look at a difference of the data to see if it achieves stationarity, 

```{r}
ggtsdisplay(diff(v3))
```

Now we set aside our training and testing sets. 

```{r}
c(train, test, horizon) %<-% train_test_split(v3, 0.8)
```


#### Data Modeling

*Simple Exponential Smoothing* and *Holt's Method*


```{r}
set.seed(123)
ses.fit <- ses(train, h = horizon)
ses.acc <- c(v3 = accuracy(ses.fit, test)['Test set', 'MAPE'])
holt.fit <- holt(train, damped=TRUE, h = horizon)
holt.acc <- c(v3 = accuracy(holt.fit, test)['Test set', 'MAPE'])
cbind(ses = ses.acc, holt = holt.acc)
```

```{r}
rbind(holt_pval = Box.test(residuals(holt.fit))$p.value,
      ses_pval = Box.test(residuals(ses.fit))$p.value)
```

The p-values are very low. These models do not fit the data well. 

```{r}
autoplot(train) +
  autolayer(ses.fit, series = "ses") +
  autolayer(holt.fit, alpha = 0.4, series = "holt") +
  autolayer(test, series = "test data") + 
  ylab("")
```

*ETS Modeling*  

```{r}
set.seed(123)
ets.fit <- ets(train)
ets.fit
```

```{r}
set.seed(123)
ets.fc <- forecast(ets.fit, h = horizon)
ets.acc <- c(v3 = accuracy(ets.fc, test)['Test set', 'MAPE'])

cbind(ses = ses.acc, holt = holt.acc, ets = ets.acc)
```

```{r}
checkresiduals(ets.fc)
```
We can see from the low p-value that this model also does not fit the data very well, 

```{r}
autoplot(train) +
  autolayer(ets.fc, series = "ets") + 
  autolayer(test, series = "test data") +
  ylab("")
```


*ARIMA modeling*

```{r}
set.seed(123)
train |>
  auto.arima(lambda = 0) |>
  forecast(h = horizon) |>
  checkresiduals()
```

```{r}
set.seed(123)
arima.fc <- train |>
  auto.arima(lambda=0) |>
  forecast(h=horizon)
```

```{r}
set.seed(123)
arima.acc <- c(v3 = accuracy(arima.fc, test)['Test set', 'MAPE'])
arima.acc
```

```{r}
autoplot(train) +
  autolayer(arima.fc, series = "arima") +
  autolayer(test, series = "test data") +
  ylab("")
```


This model also does not fit the data well. 

#### Results

```{r}
s2v3.results <- cbind(ses = ses.acc, holt = holt.acc, ets = ets.acc, arima = arima.acc)
cat("\tMAPE results by model - S02\n\n")
rbind(s2v2.results,s2v3.results)
```


# S03   

```{r}
par(mfrow = c(1,2))

s3 |>
  select(c(Var05,Var07)) |>
  ts() |>
  autoplot(facets = TRUE, main = "S03") +
  ylab('')

s3 |>
  ggplot(aes(x = Var05, y = Var07)) +
  geom_point()
```

We can see that the data are very similiar and have a strong positive correlation. 

## Var05  

#### Exploratory Data Analysis

```{r}
v5 <- ts(s3$Var05)
ggtsdisplay(v5)
```

* The data is *non-stationary*. 
* There is an upward trend over time. 
* There is some cyclicity, but no discernible seasonality. 
* The *ACF* plot tails off over time, indicating significance in the autocorrelation and presence of an AR component. The PACF cuts off at lag 2, indicating an AR(2) component. 
* There are some missing values. 
* There are some outliers present. 

```{r}
gglagplot(v5)
```

The *lagplot* indicates a positive linear relationship across lags. 


#### Data Preparation 

Dealing with outliers and missing values, 

```{r}
v5 <- v5 |>
  tsclean(lambda = "auto") |>
  na_ma()

ggtsdisplay(v5)
```

Let's difference the data and see if it achieves stationarity, 

```{r}
checkresiduals(diff(v5))
```

Now we set aside our training and testing sets. 

```{r}
c(train, test, horizon) %<-% train_test_split(v5, 0.8)
```

#### Data Modeling

*Simple Exponential Smoothing* and *Holt's Method*


```{r}
set.seed(123)
ses.fit <- ses(train, h = horizon)
ses.acc <- c(v5 = accuracy(ses.fit, test)['Test set', 'MAPE'])
holt.fit <- holt(train, damped=TRUE, h = horizon)
holt.acc <- c(v5 = accuracy(holt.fit, test)['Test set', 'MAPE'])
cbind(ses = ses.acc, holt = holt.acc)
```

```{r}
rbind(holt_pval = Box.test(residuals(holt.fit))$p.value,
      ses_pval = Box.test(residuals(ses.fit))$p.value)
```

```{r}
autoplot(train) +
  autolayer(ses.fit, series = "ses") +
  autolayer(holt.fit, alpha = 0.4, series = "holt") +
  autolayer(test, series = "test data") +
  ylab("")
```

*ETS Modeling*  

```{r}
set.seed(123)
ets.fit <- ets(train)
ets.fit
```

```{r}
set.seed(123)
ets.fc <- forecast(ets.fit, h = horizon)
ets.acc <- c(v5 = accuracy(ets.fc, test)['Test set', 'MAPE'])

cbind(ses = ses.acc, holt = holt.acc, ets = ets.acc)
```

```{r}
checkresiduals(ets.fc)
```

```{r}
autoplot(train) +
  autolayer(ets.fc, series = "ets") + 
  autolayer(test, series = "test data") +
  ylab("")
```


*ARIMA modeling*

```{r}
set.seed(123)
train |>
  auto.arima(lambda = 0) |>
  forecast(h = horizon) |>
  checkresiduals()
```

```{r}
set.seed(123)
arima.fc <- train |>
  auto.arima(lambda=0) |>
  forecast(h=horizon)
```


```{r}
set.seed(123)
arima.acc <- c(v5 = accuracy(arima.fc, test)['Test set', 'MAPE'])
arima.acc
```

```{r}
autoplot(train) +
  autolayer(arima.fc, series = "arima") +
  autolayer(test, series = "test data") +
  ylab("")
```


#### Results

```{r}
s3v5.results <- cbind(ses = ses.acc, holt = holt.acc, ets = ets.acc, arima = arima.acc)
s3v5.results
```

## Var07  

#### Exploratory Data Analysis

```{r}
v7 <- ts(s3$Var07)
ggtsdisplay(v7)
```

* The data is *non-stationary*. 
* There is an upward trend over time. 
* There is some cyclicity, but no discernible seasonality. 
* The *ACF* plot tails off over time, indicating significance in the autocorrelation and presence of an AR component. The PACF cuts off at lag 2, indicating an AR(2) component. 
* There are some missing values. 
* There are some outliers present. 

```{r}
gglagplot(v7)
```

The *lagplot* indicates a positive linear relationship across lags. 


#### Data Preparation 

Dealing with outliers and missing values, 

```{r}
v7 <- v7 |>
  tsclean(lambda = "auto") |>
  na_ma()

ggtsdisplay(v7)
```

We've been checking differences manually, but we can also call the `ndiffs` function to determine the appropriate number of first differences, 

```{r}
ndiffs(v7)
```

One difference is required to make the `v7` data stationary.

Now we set aside our training and testing sets. 

```{r}
c(train, test, horizon) %<-% train_test_split(v7, 0.8)
```

#### Data Modeling

*Simple Exponential Smoothing* and *Holt's Method*


```{r}
set.seed(123)
ses.fit <- ses(train, h = horizon)
ses.acc <- c(v7 = accuracy(ses.fit, test)['Test set', 'MAPE'])
holt.fit <- holt(train, damped=TRUE, h = horizon)
holt.acc <- c(v7 = accuracy(holt.fit, test)['Test set', 'MAPE'])
cbind(ses = ses.acc, holt = holt.acc)
```

```{r}
rbind(holt_pval = Box.test(residuals(holt.fit))$p.value,
      ses_pval = Box.test(residuals(ses.fit))$p.value)
```

```{r}
autoplot(train) +
  autolayer(ses.fit, series = "ses") +
  autolayer(holt.fit, alpha = 0.4, series = "holt") +
  autolayer(test, series = "test data") +
  ylab("")
```

*ETS Modeling*  

```{r}
set.seed(123)
ets.fit <- ets(train)
ets.fit
```

```{r}
set.seed(123)
ets.fc <- forecast(ets.fit, h = horizon)
ets.acc <- c(v7 = accuracy(ets.fc, test)['Test set', 'MAPE'])

cbind(ses = ses.acc, holt = holt.acc, ets = ets.acc)
```

```{r}
checkresiduals(ets.fc)
```

```{r}
autoplot(train) +
  autolayer(ets.fc, series = "ets") + 
  autolayer(test, series = "test data") +
  ylab("")
```


*ARIMA modeling*

```{r}
set.seed(123)
train |>
  auto.arima(lambda = 0) |>
  forecast(h = horizon) |>
  checkresiduals()
```

```{r}
set.seed(123)
arima.fc <- train |>
  auto.arima(lambda=0) |>
  forecast(h=horizon)
```


```{r}
set.seed(123)
arima.acc <- c(v7 = accuracy(arima.fc, test)['Test set', 'MAPE'])
arima.acc
```

```{r}
autoplot(train) +
  autolayer(arima.fc, series = "arima") +
  autolayer(test, series = "test data") +
  ylab("")
```


#### Results

```{r}
s3v7.results <- cbind(ses = ses.acc, holt = holt.acc, ets = ets.acc, arima = arima.acc)
cat("\tMAPE results by model - S03\n\n")
rbind(s3v5.results,s3v7.results)
```
